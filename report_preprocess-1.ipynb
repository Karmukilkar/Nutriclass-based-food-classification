{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "547550cf",
   "metadata": {},
   "source": [
    "# Food Nutrition Dataset: Data Preprocessing & EDA Report\n",
    "\n",
    "This notebook presents a comprehensive workflow for data preprocessing and exploratory data analysis (EDA) on a food nutrition dataset. The steps include data cleaning, visualization, feature engineering, and feature importance analysis to prepare the data for modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00fd5a5",
   "metadata": {},
   "source": [
    "## 1. Importing Required Libraries\n",
    "\n",
    "We begin by importing essential libraries for data manipulation, visualization, and preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c44dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39aca8a",
   "metadata": {},
   "source": [
    "## 2. Loading the Dataset\n",
    "\n",
    "Load the food nutrition dataset and display its first few rows and shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b88f081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'food_data.csv' with your actual file path if needed\n",
    "df = pd.read_csv(\"food_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e8866",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "430c8cf4",
   "metadata": {},
   "source": [
    "## 3. Initial Data Exploration\n",
    "\n",
    "Get an overview of the dataset structure and data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f139ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c2cb36",
   "metadata": {},
   "source": [
    "## 4. Descriptive Statistics\n",
    "\n",
    "Generate descriptive statistics for both numerical and categorical columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4adf3cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60f83e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical columns\n",
    "df.describe(exclude='float')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42e001d",
   "metadata": {},
   "source": [
    "## 5. Data Visualization\n",
    "\n",
    "Visualize average calories by meal type and explore distributions of continuous and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f439a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,4))\n",
    "sns.barplot(x=df[\"Meal_Type\"], y=df[\"Calories\"])\n",
    "plt.title(\"Average Calories by Meal Type\")\n",
    "plt.xlabel(\"Meal Type\")\n",
    "plt.ylabel(\"Average Calories\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8acb556",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of continuous variables\n",
    "for col in df.select_dtypes(include=[np.number]).columns:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.kdeplot(x=df[col], fill=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394cfc5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of categorical variables\n",
    "for col in df.select_dtypes(include=['object', 'bool']).columns:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x=df[col])\n",
    "    plt.title(f'Count of {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ab493f",
   "metadata": {},
   "source": [
    "## 6. Null Values Treatment\n",
    "\n",
    "Identify missing values, calculate their percentage, and drop rows with missing values if the proportion is small."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1402a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of null values\n",
    "print(df.isnull().sum())\n",
    "# Percentage of null values\n",
    "print(df.isnull().mean() * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f58b1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values if proportion is small\n",
    "df.dropna(inplace=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e793dc6e",
   "metadata": {},
   "source": [
    "## 7. Categorical and Numerical Variable Identification\n",
    "\n",
    "Identify and print the names and counts of categorical and numerical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df7295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars = df.select_dtypes(include=['float64', 'int64']).columns\n",
    "cat_vars = df.select_dtypes(include=['object', 'bool']).columns\n",
    "print(\"Numerical variables:\", list(num_vars), \"Count:\", len(num_vars))\n",
    "print(\"Categorical variables:\", list(cat_vars), \"Count:\", len(cat_vars))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448ab2cc",
   "metadata": {},
   "source": [
    "## 8. Distribution Analysis\n",
    "\n",
    "Plot the distributions of continuous and categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d61123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Continuous variables\n",
    "for col in num_vars:\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    sns.kdeplot(x=df[col], fill=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9756df20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical variables\n",
    "for col in cat_vars:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(x=df[col])\n",
    "    plt.title(f'Count of {col}')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d2ebd2",
   "metadata": {},
   "source": [
    "## 9. Outlier Detection and Treatment\n",
    "\n",
    "Detect outliers in numerical features using boxplots, and cap outliers using the IQR method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2aa6ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplots for outlier detection\n",
    "for col in num_vars:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=df[col], color='red')\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40da898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capping outliers using IQR\n",
    "def cap_outliers(series):\n",
    "    Q1 = series.quantile(0.25)\n",
    "    Q3 = series.quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower = Q1 - 1.5 * IQR\n",
    "    upper = Q3 + 1.5 * IQR\n",
    "    return series.clip(lower, upper)\n",
    "\n",
    "df[num_vars] = df[num_vars].apply(cap_outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d566ac6",
   "metadata": {},
   "source": [
    "## 10. Duplicate Entry Removal\n",
    "\n",
    "Check for duplicate rows and remove them from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a71799d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of duplicate rows:\", df.duplicated().sum())\n",
    "df.drop_duplicates(inplace=True)\n",
    "print(\"Number of duplicate rows after removal:\", df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61dedd5",
   "metadata": {},
   "source": [
    "## 11. Standardizing Numerical Features\n",
    "\n",
    "Apply StandardScaler to numerical features to standardize them for further analysis or modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12bde4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "df[num_vars] = scaler.fit_transform(df[num_vars])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c11eb8",
   "metadata": {},
   "source": [
    "## 12. Categorical Variable Encoding\n",
    "\n",
    "Encode boolean categorical variables as 0/1 and apply label encoding to other categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd292495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boolean encoding\n",
    "for col in df.select_dtypes(include='bool').columns:\n",
    "    df[col] = df[col].astype(int)\n",
    "\n",
    "# Label encoding for object type categorical variables\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include='object').columns:\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e50a76",
   "metadata": {},
   "source": [
    "## 13. Feature Engineering\n",
    "\n",
    "Engineer new features or transform existing ones as needed for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab63021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: No new features engineered in this workflow, but this is where you would add them.\n",
    "# df['New_Feature'] = df['Some_Column'] * 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c2e5ec",
   "metadata": {},
   "source": [
    "## 14. Feature Importance Analysis\n",
    "\n",
    "Use RandomForestClassifier to determine feature importances, visualize the top features, and select the most relevant ones for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c18b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'Food_Name' is the target variable for demonstration\n",
    "X = df.drop(columns=['Food_Name'])\n",
    "y = df['Food_Name']\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=250, random_state=42)\n",
    "rf.fit(X, y)\n",
    "importances = rf.feature_importances_\n",
    "feature_names = X.columns\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "feat_imp_df = pd.DataFrame({\n",
    "    'Feature': feature_names,\n",
    "    'Importance': importances * 100\n",
    "}).sort_values('Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cbe43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top features\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(x='Importance', y='Feature', data=feat_imp_df.head(9), palette='viridis')\n",
    "plt.title('Top 9 Feature Importance Scores')\n",
    "plt.xlabel('Importance Score (%)')\n",
    "plt.ylabel('Features')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385990e4",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Summary:**  \n",
    "This notebook covered the end-to-end preprocessing and EDA workflow for the food nutrition dataset, including data cleaning, visualization, feature engineering, and feature importance analysis. The processed data is now ready for model building and further analysis."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
